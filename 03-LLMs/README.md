# Large Language Models (LLMs)

This section focuses on Large Language Models, their architectures, training, and practical applications.

## Topics

- **Concepts**: FM, LLM, Tokens, Embeddings, etc.
- **Architectures**: GPT, BERT, T5, LLaMA, Claude, and other LLM architectures
- **Training-and-Fine-Tuning**: Pre-training, fine-tuning, RLHF, LoRA, QLoRA, and other techniques
- **Prompt-Engineering**: Techniques for effective prompting, few-shot learning, chain-of-thought
- **RAG**: Retrieval-Augmented Generation - combining LLMs with external knowledge
- **Popular-Models**: Overview of GPT-4, Claude, Gemini, LLaMA, Mistral, etc.

## Key Focus Areas

- Understanding how LLMs work
- Techniques for customizing and deploying LLMs
- Best practices for prompt engineering
- Building RAG applications
